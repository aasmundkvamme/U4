{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "import pyodbc\n",
    "import os\n",
    "import io\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "idag = datetime.now()\n",
    "igår = idag - timedelta(days=1)\n",
    "år = idag.year\n",
    "måned = idag.month\n",
    "dag = idag.day\n",
    "if måned <= 7:\n",
    "    termin = \"VÅR\"\n",
    "else:\n",
    "    termin = \"HØST\"\n",
    "\n",
    "CD2_base_url = \"https://api-gateway.instructure.com\"\n",
    "CD2_client_id=\"eu-west-1#1505cc4e-f9aa-41d5-a364-214699ebe66b\"\n",
    "CD2_client_secret=\"H0BAdlBVfSXps5KmKNFEu9e_fXhpDGc_ksjD0Fm2cH4\"\n",
    "conn_str='Driver={ODBC Driver 18 for SQL Server};Server=tcp:hvl-data-db-server.database.windows.net,1433;Database=HVL-db;Uid=Admin-hvl;Pwd=BergenByErFin1;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_finn_sist_oppdatert(tabell):\n",
    "    \"\"\"\n",
    "    Returner den siste oppdateringstida for den gitte tabellen fra akv_sist_oppdatert-tabellen.\n",
    "    Hvis ingen dato er gitt (eller vi ikkje får kontakt med databasen), returner igår.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pyodbc.connect(conn_str) as connection:\n",
    "            cursor = connection.cursor()\n",
    "            query = \"\"\"\n",
    "            SELECT [sist_oppdatert] FROM [dbo].[akv_sist_oppdatert]\n",
    "            WHERE [tabell] = ?\n",
    "            \"\"\"\n",
    "            cursor.execute(query, (tabell,))\n",
    "            row = cursor.fetchone()\n",
    "            if row:\n",
    "                logging.debug(f\"{tabell} er sist oppdatert (Azure): {row[0].isoformat() + 'Z'}\")\n",
    "                return row[0].isoformat() + \"Z\"\n",
    "            \n",
    "    except pyodbc.Error as exc:\n",
    "        logging.debug(f\"{tabell} er sist oppdatert (lokal): {(date.today() - timedelta(days=1)).isoformat() + 'Z'}\") \n",
    "        return (date.today() - timedelta(days=1)).isoformat() + \"Z\"\n",
    "\n",
    "\n",
    "def akv_lagre_sist_oppdatert(tabell, dato):\n",
    "    \"\"\"\n",
    "    Lagre datoen for siste oppdatering av tabell i Azure eller lokalt (dersom vi ikkje får kontakt med databasen).\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with pyodbc.connect(conn_str) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            query = \"\"\"\n",
    "            MERGE INTO [dbo].[akv_sist_oppdatert] AS target \n",
    "            USING (VALUES (?, ?)) AS source (tabell, sist_oppdatert) \n",
    "            ON target.[tabell] = source.[tabell]\n",
    "            WHEN MATCHED THEN\n",
    "                UPDATE SET target.[sist_oppdatert] = source.[sist_oppdatert]\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT ([tabell], [sist_oppdatert]) VALUES (source.[tabell], source.[sist_oppdatert]);\n",
    "            \"\"\" \n",
    "            cursor.execute(query, (tabell, dato))\n",
    "            conn.commit()\n",
    "            logging.debug(f\"{tabell} er sist oppdatert (Azure): {dato}\")\n",
    "    except pyodbc.Error as e:\n",
    "        with open(f'sist_oppdatert_{tabell}.txt', 'w') as f_out:\n",
    "            f_out.write(dato)\n",
    "            logging.debug(f\"{tabell} er sist oppdatert (lokal): {dato}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_hent_CD2_access_token():\n",
    "    be_om_access_token = requests.request(\n",
    "        \"POST\",\n",
    "        f\"{CD2_base_url}/ids/auth/login\",\n",
    "        data={'grant_type': 'client_credentials'},\n",
    "        auth=(CD2_client_id, CD2_client_secret)\n",
    "        )\n",
    "    if be_om_access_token.status_code == 200:\n",
    "        CD2_access_token = be_om_access_token.json()['access_token']\n",
    "        return CD2_access_token\n",
    "    else:\n",
    "        feilmelding = f\"Klarte ikkje å skaffe access_token, feil {be_om_access_token.status_code}\"\n",
    "        logging.error(feilmelding)\n",
    "        return feilmelding\n",
    "\n",
    "\n",
    "def akv_hent_CD2_filar(innfil, token, svar):\n",
    "    requesturl = f\"{CD2_base_url}/dap/object/url\"\n",
    "    payload = f\"{svar['objects']}\"\n",
    "    payload = payload.replace('\\'', '\\\"')\n",
    "    headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "    r4 = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "    if r4.status_code == 200:\n",
    "        respons4 = r4.json()\n",
    "        url = respons4['urls'][innfil]['url']\n",
    "        data = requests.request(\"GET\", url)\n",
    "        buffer = io.BytesIO(data.content)\n",
    "        with gzip.GzipFile(fileobj=buffer, mode='rb') as utpakka_fil:\n",
    "            utpakka_data = utpakka_fil.read().decode()\n",
    "    return utpakka_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_les_CD2_tabell(tabell):\n",
    "    CD2_access_token = akv_hent_CD2_access_token()\n",
    "    headers = {'x-instauth': CD2_access_token, 'Content-Type': 'text/plain'}\n",
    "    sist_oppdatert = akv_finn_sist_oppdatert(tabell)\n",
    "    payload = '{\"format\": \"csv\", \"since\": \\\"%s\\\"}' % (sist_oppdatert)\n",
    "    requesturl = f\"{CD2_base_url}/dap/query/canvas/table/{tabell}/data\"\n",
    "    print(f\"Sender søk til {requesturl}\")\n",
    "    try:\n",
    "        r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        r.raise_for_status()\n",
    "        respons = r.json()\n",
    "        id = respons['id']\n",
    "        vent = True\n",
    "        while vent:\n",
    "            requesturl2 = f\"{CD2_base_url}/dap//job/{id}\"\n",
    "            r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "            time.sleep(5)\n",
    "            respons2 = r2.json()\n",
    "            print(respons2)\n",
    "            if respons2['status'] == \"complete\":\n",
    "                vent = False\n",
    "                filar = respons2['objects']\n",
    "        dr_liste = []\n",
    "        print(filar)\n",
    "        for fil in filar:\n",
    "            data = io.StringIO(akv_hent_CD2_filar(fil['id'], CD2_access_token, respons2))\n",
    "            df = pd.read_csv(data, sep=\",\")\n",
    "            dr_liste.append(df)\n",
    "        alledata = pd.concat(df for df in dr_liste if not df.empty)\n",
    "        return alledata, sist_oppdatert, respons2['until']\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabell = \"Canvas_Enrollments\"\n",
    "if os.path.exists(f'loggfil-{tabell}.log'):\n",
    "    os.remove(f'loggfil-{tabell}.log')\n",
    "\n",
    "# Opprett logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)  # Sett ønsket loggnivå\n",
    "\n",
    "# Opprett formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Opprett filhandler for å logge til fil\n",
    "file_handler = logging.FileHandler(f'loggfil-{tabell}.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Opprett konsollhandler for å logge til konsollen\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Legg til handlerne i loggeren\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_Canvas_Enrollments = time.perf_counter()\n",
    "with pyodbc.connect(conn_str) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ALL * FROM [stg].[Canvas_Terms]\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchall()\n",
    "        terminar = []\n",
    "        for t in row:\n",
    "            try:\n",
    "                term_id = t[0]\n",
    "                name = t[1]\n",
    "                start_at = t[2]\n",
    "                end_at = t[3]\n",
    "                created_at = t[4]\n",
    "                terminar.append([term_id, name, start_at, end_at, created_at])\n",
    "            except IndexError:\n",
    "                logger.error(\"Ingen data i denne raden: {t}\")\n",
    "    except pyodbc.Error as e:\n",
    "        logger.error(f\"Feil: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aktuelle_terminar = []\n",
    "try:\n",
    "    for t in terminar:\n",
    "        desimal = int(år) + 0.5*(termin == 'HØST')\n",
    "        if '-' in t[1]:\n",
    "            start_termin = t[1].split('-')[0]\n",
    "            slutt_termin = t[1].split('-')[1]\n",
    "            start_år = start_termin.split(' ')[0]\n",
    "            slutt_år = slutt_termin.split(' ')[0]\n",
    "            start_semester = start_termin.split(' ')[1]\n",
    "            slutt_semester = slutt_termin.split(' ')[1]\n",
    "            start_desimal = int(start_år) + 0.5*(start_semester == 'HØST')\n",
    "            slutt_desimal = int(slutt_år) + 0.5*(slutt_semester == 'HØST')\n",
    "            if start_desimal <= desimal <= slutt_desimal:\n",
    "                aktuelle_terminar.append(t[0])\n",
    "            else:\n",
    "                pass\n",
    "        elif t[1] == f\"{str(år)} {termin}\":\n",
    "            aktuelle_terminar.append(t[0])\n",
    "        else:\n",
    "            pass\n",
    "except:\n",
    "    logger.error(f\"Feil: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyodbc.connect(conn_str) as conn:\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT ALL * FROM [stg].[Canvas_Courses]\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        row = cursor.fetchall()\n",
    "        aktuelle_emne = []\n",
    "        for emne in row:\n",
    "            try:\n",
    "                if emne[4] in aktuelle_terminar:\n",
    "                    aktuelle_emne.append(emne[0])\n",
    "            except IndexError:\n",
    "                pass\n",
    "    except pyodbc.Error as e:\n",
    "        logger.error(f\"Feil: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sender søk til https://api-gateway.instructure.com/dap/query/canvas/table/enrollments/data\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'running', 'expires_at': '2024-11-29T09:56:06Z'}\n",
      "{'id': '01de4067-957f-44f2-98b2-ba5575f0910f', 'status': 'complete', 'objects': [{'id': '01de4067-957f-44f2-98b2-ba5575f0910f/part-00000-5d458a2f-5f4c-41bc-81b0-9d8c7fea8dba-c000.csv.gz'}, {'id': '01de4067-957f-44f2-98b2-ba5575f0910f/part-00002-5d458a2f-5f4c-41bc-81b0-9d8c7fea8dba-c000.csv.gz'}], 'expires_at': '2024-11-29T09:56:06Z', 'schema_version': 1, 'since': '2024-10-24T07:06:15Z', 'until': '2024-11-28T07:48:18Z'}\n",
      "[{'id': '01de4067-957f-44f2-98b2-ba5575f0910f/part-00000-5d458a2f-5f4c-41bc-81b0-9d8c7fea8dba-c000.csv.gz'}, {'id': '01de4067-957f-44f2-98b2-ba5575f0910f/part-00002-5d458a2f-5f4c-41bc-81b0-9d8c7fea8dba-c000.csv.gz'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4066/3018563503.py:27: DtypeWarning: Columns (14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "tabell = \"enrollments\"\n",
    "resultat = akv_les_CD2_tabell(tabell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4066/2325093602.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  enrollments.loc[:,'sis_user_id'] = ''\n"
     ]
    }
   ],
   "source": [
    "enrollments = resultat[0][['key.id', 'value.user_id', 'value.course_id', 'value.type', 'value.created_at', 'value.updated_at', 'value.workflow_state', 'value.total_activity_time', 'value.last_activity_at']]\n",
    "enrollments.loc[:,'sis_user_id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key.id</th>\n",
       "      <th>value.user_id</th>\n",
       "      <th>value.course_id</th>\n",
       "      <th>value.type</th>\n",
       "      <th>value.created_at</th>\n",
       "      <th>value.updated_at</th>\n",
       "      <th>value.workflow_state</th>\n",
       "      <th>value.total_activity_time</th>\n",
       "      <th>value.last_activity_at</th>\n",
       "      <th>sis_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1256959</td>\n",
       "      <td>67355</td>\n",
       "      <td>25541</td>\n",
       "      <td>StudentEnrollment</td>\n",
       "      <td>2023-12-17T02:29:49.872Z</td>\n",
       "      <td>2024-09-24T09:56:44.315Z</td>\n",
       "      <td>active</td>\n",
       "      <td>73262.0</td>\n",
       "      <td>2024-06-10T14:04:26.182Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282347</td>\n",
       "      <td>47509</td>\n",
       "      <td>25834</td>\n",
       "      <td>StudentEnrollment</td>\n",
       "      <td>2024-01-07T07:42:53.679Z</td>\n",
       "      <td>2024-09-24T10:00:03.357Z</td>\n",
       "      <td>active</td>\n",
       "      <td>67998.0</td>\n",
       "      <td>2024-05-31T07:54:14.812Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1262583</td>\n",
       "      <td>94554</td>\n",
       "      <td>25541</td>\n",
       "      <td>StudentEnrollment</td>\n",
       "      <td>2023-12-19T16:12:55.612Z</td>\n",
       "      <td>2024-09-24T09:40:55.958Z</td>\n",
       "      <td>active</td>\n",
       "      <td>277491.0</td>\n",
       "      <td>2024-11-14T12:34:38.652Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1249218</td>\n",
       "      <td>79426</td>\n",
       "      <td>24602</td>\n",
       "      <td>StudentEnrollment</td>\n",
       "      <td>2023-12-15T06:12:21.014Z</td>\n",
       "      <td>2024-09-24T09:45:33.084Z</td>\n",
       "      <td>active</td>\n",
       "      <td>193122.0</td>\n",
       "      <td>2024-10-28T11:18:08.898Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1256585</td>\n",
       "      <td>83726</td>\n",
       "      <td>25881</td>\n",
       "      <td>StudentEnrollment</td>\n",
       "      <td>2023-12-16T16:14:38.638Z</td>\n",
       "      <td>2024-09-24T09:43:09.498Z</td>\n",
       "      <td>active</td>\n",
       "      <td>502315.0</td>\n",
       "      <td>2024-11-10T08:58:44.358Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220139</th>\n",
       "      <td>1456022</td>\n",
       "      <td>5928</td>\n",
       "      <td>30211</td>\n",
       "      <td>TeacherEnrollment</td>\n",
       "      <td>2024-11-27T16:35:41.161Z</td>\n",
       "      <td>2024-11-27T16:38:10.879Z</td>\n",
       "      <td>active</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2024-11-28T06:49:08.588Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220140</th>\n",
       "      <td>1456027</td>\n",
       "      <td>4593</td>\n",
       "      <td>28704</td>\n",
       "      <td>ObserverEnrollment</td>\n",
       "      <td>2024-11-28T07:05:33.004Z</td>\n",
       "      <td>2024-11-28T07:05:33.004Z</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220141</th>\n",
       "      <td>1456026</td>\n",
       "      <td>4591</td>\n",
       "      <td>28704</td>\n",
       "      <td>ObserverEnrollment</td>\n",
       "      <td>2024-11-28T07:05:14.796Z</td>\n",
       "      <td>2024-11-28T07:05:14.796Z</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220142</th>\n",
       "      <td>1456025</td>\n",
       "      <td>21263</td>\n",
       "      <td>28704</td>\n",
       "      <td>ObserverEnrollment</td>\n",
       "      <td>2024-11-28T07:04:55.457Z</td>\n",
       "      <td>2024-11-28T07:04:55.457Z</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220143</th>\n",
       "      <td>1456024</td>\n",
       "      <td>28525</td>\n",
       "      <td>29252</td>\n",
       "      <td>TeacherEnrollment</td>\n",
       "      <td>2024-11-28T07:00:19.324Z</td>\n",
       "      <td>2024-11-28T07:00:19.324Z</td>\n",
       "      <td>invited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220144 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key.id  value.user_id  value.course_id          value.type  \\\n",
       "0       1256959          67355            25541   StudentEnrollment   \n",
       "1       1282347          47509            25834   StudentEnrollment   \n",
       "2       1262583          94554            25541   StudentEnrollment   \n",
       "3       1249218          79426            24602   StudentEnrollment   \n",
       "4       1256585          83726            25881   StudentEnrollment   \n",
       "...         ...            ...              ...                 ...   \n",
       "220139  1456022           5928            30211   TeacherEnrollment   \n",
       "220140  1456027           4593            28704  ObserverEnrollment   \n",
       "220141  1456026           4591            28704  ObserverEnrollment   \n",
       "220142  1456025          21263            28704  ObserverEnrollment   \n",
       "220143  1456024          28525            29252   TeacherEnrollment   \n",
       "\n",
       "                value.created_at          value.updated_at  \\\n",
       "0       2023-12-17T02:29:49.872Z  2024-09-24T09:56:44.315Z   \n",
       "1       2024-01-07T07:42:53.679Z  2024-09-24T10:00:03.357Z   \n",
       "2       2023-12-19T16:12:55.612Z  2024-09-24T09:40:55.958Z   \n",
       "3       2023-12-15T06:12:21.014Z  2024-09-24T09:45:33.084Z   \n",
       "4       2023-12-16T16:14:38.638Z  2024-09-24T09:43:09.498Z   \n",
       "...                          ...                       ...   \n",
       "220139  2024-11-27T16:35:41.161Z  2024-11-27T16:38:10.879Z   \n",
       "220140  2024-11-28T07:05:33.004Z  2024-11-28T07:05:33.004Z   \n",
       "220141  2024-11-28T07:05:14.796Z  2024-11-28T07:05:14.796Z   \n",
       "220142  2024-11-28T07:04:55.457Z  2024-11-28T07:04:55.457Z   \n",
       "220143  2024-11-28T07:00:19.324Z  2024-11-28T07:00:19.324Z   \n",
       "\n",
       "       value.workflow_state  value.total_activity_time  \\\n",
       "0                    active                    73262.0   \n",
       "1                    active                    67998.0   \n",
       "2                    active                   277491.0   \n",
       "3                    active                   193122.0   \n",
       "4                    active                   502315.0   \n",
       "...                     ...                        ...   \n",
       "220139               active                      165.0   \n",
       "220140               active                        NaN   \n",
       "220141               active                        NaN   \n",
       "220142               active                        NaN   \n",
       "220143              invited                        NaN   \n",
       "\n",
       "          value.last_activity_at sis_user_id  \n",
       "0       2024-06-10T14:04:26.182Z              \n",
       "1       2024-05-31T07:54:14.812Z              \n",
       "2       2024-11-14T12:34:38.652Z              \n",
       "3       2024-10-28T11:18:08.898Z              \n",
       "4       2024-11-10T08:58:44.358Z              \n",
       "...                          ...         ...  \n",
       "220139  2024-11-28T06:49:08.588Z              \n",
       "220140                       NaN              \n",
       "220141                       NaN              \n",
       "220142                       NaN              \n",
       "220143                       NaN              \n",
       "\n",
       "[220144 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =enrollments.iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_query = \"\"\"\n",
    "    MERGE INTO [stg].[Canvas_Enrollments] AS target\n",
    "    USING (SELECT ?, ?, ?, ?, ?, CONVERT(datetime, ?, 127), CONVERT(datetime, ?, 127), ?, ?, ?, ?, CONVERT(datetime, ?, 127)) AS source (\n",
    "        [enrollment_id],\n",
    "        [user_id],\n",
    "        [sis_user_id],\n",
    "        [course_id],\n",
    "        [type],\n",
    "        [created_at],\n",
    "        [updated_at],\n",
    "        [start_at],\n",
    "        [end_at],\n",
    "        [enrollment_state],\n",
    "        [total_activity_time],\n",
    "        [last_activity_at]\n",
    "    )\n",
    "    ON target.[enrollment_id] = source.[enrollment_id]\n",
    "    WHEN MATCHED THEN\n",
    "        UPDATE SET target.[user_id]= source.[user_id],\n",
    "            target.[sis_user_id] = source.[sis_user_id],\n",
    "            target.[course_id] = source.[course_id],\n",
    "            target.[type] = source.[type],\n",
    "            target.[created_at] = source.[created_at],\n",
    "            target.[updated_at] = source.[updated_at],\n",
    "            target.[start_at] = source[start_at],\n",
    "            target.[end_at] = source.[end_at],\n",
    "            target.[enrollment_state] = source.[enrollment_state],\n",
    "            target.[total_activity_time] = source.[total_activity_time],\n",
    "            target.[last_activity_at] = source.[last_activity_at]\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT ([enrollment_id],\n",
    "            [user_id],\n",
    "            [sis_user_id],\n",
    "            [course_id],\n",
    "            [type],\n",
    "            [created_at],\n",
    "            [updated_at],\n",
    "            [start_at],\n",
    "            [end_at],\n",
    "            [enrollment_state],\n",
    "            [total_activity_time],\n",
    "            [last_activity_at]\n",
    "        )\n",
    "        VALUES (source.[enrollment_id],\n",
    "            source.[user_id],\n",
    "            source.[sis_user_id],\n",
    "            source.[course_id],\n",
    "            source.[type],\n",
    "            source.[created_at],\n",
    "            source.[updated_at],\n",
    "            source.[start_at],\n",
    "            source.[end_at],\n",
    "            source.[enrollment_state],\n",
    "            source.[total_activity_time],\n",
    "            source.[last_activity_at]\n",
    "        );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4066/1505484284.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['value.total_activity_time'] = None if pd.isna(s['value.total_activity_time']) else s['value.total_activity_time']\n",
      "/tmp/ipykernel_4066/1505484284.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['value.last_activity_at'] = None if pd.isna(s['value.last_activity_at']) else s['value.last_activity_at']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_at'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.total_activity_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.total_activity_time\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.total_activity_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.last_activity_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.last_activity_at\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.last_activity_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_at'"
     ]
    }
   ],
   "source": [
    "s['value.total_activity_time'] = None if pd.isna(s['value.total_activity_time']) else s['value.total_activity_time']\n",
    "s['value.last_activity_at'] = None if pd.isna(s['value.last_activity_at']) else s['value.last_activity_at']\n",
    "s['start_at'] = None if s['start_at'] == '' else s['start_at']\n",
    "s['end_at'] = None if s['end_at'] == '' else s['end_at']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'start_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_at'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pyodbc\u001b[38;5;241m.\u001b[39mconnect(conn_str) \u001b[38;5;28;01mas\u001b[39;00m cnxn:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cnxn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m----> 3\u001b[0m         cursor\u001b[38;5;241m.\u001b[39mexecute(merge_query, (\u001b[38;5;28mint\u001b[39m(s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey.id\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;28mint\u001b[39m(s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.user_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msis_user_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mint\u001b[39m(s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.course_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.type\u001b[39m\u001b[38;5;124m'\u001b[39m], s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.created_at\u001b[39m\u001b[38;5;124m'\u001b[39m], s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.updated_at\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_at\u001b[39m\u001b[38;5;124m'\u001b[39m], s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.workflow_state\u001b[39m\u001b[38;5;124m'\u001b[39m], s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.total_activity_time\u001b[39m\u001b[38;5;124m'\u001b[39m], s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue.last_activity_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m ))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start_at'"
     ]
    }
   ],
   "source": [
    "with pyodbc.connect(conn_str) as cnxn:\n",
    "    with cnxn.cursor() as cursor:\n",
    "        cursor.execute(merge_query, (int(s['key.id']), int(s['value.user_id']), s['sis_user_id'] or None, int(s['value.course_id']), s['value.type'], s['value.created_at'], s['value.updated_at'], s['start_at'], s['end_at'], s['value.workflow_state'], s['value.total_activity_time'], s['value.last_activity_at'] or None ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key.id                                        1456025\n",
       "value.user_id                                   21263\n",
       "value.course_id                                 28704\n",
       "value.type                         ObserverEnrollment\n",
       "value.created_at             2024-11-28T07:04:55.457Z\n",
       "value.updated_at             2024-11-28T07:04:55.457Z\n",
       "value.workflow_state                           active\n",
       "value.total_activity_time                        None\n",
       "value.last_activity_at                           None\n",
       "sis_user_id                                          \n",
       "Name: 220142, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
