{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "import pyodbc\n",
    "import os\n",
    "import io\n",
    "# import azure.functions as func\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "idag = datetime.now()\n",
    "igår = idag - timedelta(days=1)\n",
    "år = idag.year\n",
    "måned = idag.month\n",
    "dag = idag.day\n",
    "if måned <= 7:\n",
    "    termin = \"VÅR\"\n",
    "else:\n",
    "    termin = \"HØST\"\n",
    "\n",
    "CD2_base_url = \"https://api-gateway.instructure.com\"\n",
    "CD2_client_id = \"eu-west-1#1505cc4e-f9aa-41d5-a364-214699ebe66b\" # os.environ['CD2_client_id']\n",
    "CD2_client_secret = \"H0BAdlBVfSXps5KmKNFEu9e_fXhpDGc_ksjD0Fm2cH4\" # os.environ['CD2_client_secret']\n",
    "conn_str = os.environ[\"Connection_SQL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_hent_CD2_access_token():\n",
    "    be_om_access_token = requests.request(\n",
    "        \"POST\",\n",
    "        \"https://api-gateway.instructure.com/ids/auth/login\",\n",
    "        data={'grant_type': 'client_credentials'},\n",
    "        auth=(CD2_client_id, CD2_client_secret)\n",
    "        )\n",
    "    if be_om_access_token.status_code == 200:\n",
    "        CD2_access_token = be_om_access_token.json()['access_token']\n",
    "        return CD2_access_token\n",
    "    else:\n",
    "        feilmelding = f\"Klarte ikkje å skaffe access_token, feil {be_om_access_token.status_code}\"\n",
    "        logging.error(feilmelding)\n",
    "        return feilmelding\n",
    "\n",
    "\n",
    "def akv_finn_sist_oppdatert(tabell):\n",
    "    if os.path.exists(f\"sist_oppdatert_{tabell}.txt\"):\n",
    "        with open(f\"sist_oppdatert_{tabell}.txt\", \"r\") as f_in:\n",
    "            return f_in.read()\n",
    "    else:\n",
    "        return (datetime.now()-timedelta(days=1)).isoformat() + \"Z\"\n",
    "\n",
    "\n",
    "def akv_lagre_sist_oppdatert(tabell, sist_oppdatert):\n",
    "    with open(f\"sist_oppdatert_{tabell}.txt\", \"w\") as f:\n",
    "        f.write(sist_oppdatert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_hent_CD2_fil(innfil, token, svar):\n",
    "    try:\n",
    "        requesturl = \"https://api-gateway.instructure.com/dap/object/url\"\n",
    "        payload = f\"{svar['objects']}\"\n",
    "        payload = payload.replace('\\'', '\\\"')\n",
    "        headers = {'x-instauth': token, 'Content-Type': 'text/plain'}\n",
    "        respons = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        respons.raise_for_status()\n",
    "        fil = respons.json()\n",
    "        url = fil['urls'][innfil]['url']\n",
    "        data = requests.request(\"GET\", url)\n",
    "        buffer = io.BytesIO(data.content)\n",
    "        with gzip.GzipFile(fileobj=buffer, mode='rb') as utpakka_fil:\n",
    "            utpakka_data = utpakka_fil.read().decode()\n",
    "        return utpakka_data\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def akv_les_CD2_tabell(tabell):\n",
    "    CD2_access_token = akv_hent_CD2_access_token()\n",
    "    headers = {'x-instauth': CD2_access_token, 'Content-Type': 'text/plain'}\n",
    "    payload = '{\"format\": \"csv\", \"since\": \\\"%s\\\"}' % (forrige_oppdatering)\n",
    "    requesturl = f\"https://api-gateway.instructure.com/dap/query/canvas/table/{tabell}/data\"\n",
    "    logging.info(f\"Sender søk til {requesturl}\")\n",
    "    try:\n",
    "        start_finn_filar = time.perf_counter()\n",
    "        r = requests.request(\"POST\", requesturl, headers=headers, data=payload)\n",
    "        r.raise_for_status()\n",
    "        respons = r.json()\n",
    "        id = respons['id']\n",
    "        vent = True\n",
    "        while vent:\n",
    "            logging.info(f\"Vent til fila blir tilgjengelig: {requesturl}/job/{id}\")\n",
    "            requesturl2 = f\"https://api-gateway.instructure.com/dap//job/{id}\"\n",
    "            r2 = requests.request(\"GET\", requesturl2, headers=headers)\n",
    "            time.sleep(5)\n",
    "            respons2 = r2.json()\n",
    "            if respons2['status'] == \"complete\":\n",
    "                logging.info(f\"Fila(ne) er tilgjengeleg(e): {requesturl}/job/{id}\")\n",
    "                vent = False\n",
    "                filer = respons2['objects']\n",
    "                sist_oppdatert = respons2['until']\n",
    "        logging.info(f\"Totalt for {tabell}_finn_filer: {time.perf_counter() - start_finn_filar}\")\n",
    "    except requests.exceptions.RequestException as exc:\n",
    "        raise exc\n",
    "    dr_liste = []\n",
    "    start_les_filer = time.perf_counter()\n",
    "    for fil in filer:\n",
    "        data = io.StringIO(akv_hent_CD2_fil(fil['id'], CD2_access_token, respons2))\n",
    "        df = pd.read_csv(data, sep=\",\")\n",
    "        dr_liste.append(df)\n",
    "    alledata = pd.concat(df for df in dr_liste if not df.empty)\n",
    "    logging.info(f\"Totalt for {tabell}_les_filer: {time.perf_counter() - start_les_filer}\")\n",
    "    return alledata, sist_oppdatert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_495/1008012460.py:32: DtypeWarning: Columns (14,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "tabell = \"enrollments\"\n",
    "logging.basicConfig(filename=f'{tabell}.log', encoding='utf-8', level=logging.INFO)\n",
    "forrige_oppdatering = akv_finn_sist_oppdatert(tabell)\n",
    "alledata, sist_oppdatert = akv_les_CD2_tabell(tabell)\n",
    "akv_lagre_sist_oppdatert(tabell, sist_oppdatert)\n",
    "alledata.to_csv(\"alledata_enrollment.csv\", index=False)\n",
    "enrollments = alledata[['key.id', 'value.user_id', 'value.course_id', 'value.type', 'value.created_at', 'value.updated_at', 'value.start_at', 'value.end_at', 'value.workflow_state', 'value.total_activity_time', 'value.last_activity_at']]\n",
    "nye = enrollments[enrollments['value.created_at'] > forrige_oppdatering]\n",
    "\n",
    "# For testing lokalt. Kan fjernes etter testing.\n",
    "nye.to_csv(f\"nye_{tabell}_{sist_oppdatert[0:10]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error inserting row 187586: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187587: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187588: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187589: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187590: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187591: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187592: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187593: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187594: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187595: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187596: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187597: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187598: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187599: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187600: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187601: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187602: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187603: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187604: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187605: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187606: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187607: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187608: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187609: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187610: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187611: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187612: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187613: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187614: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187615: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187616: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187617: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187618: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187619: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187620: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187621: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187622: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187623: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187624: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187625: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187626: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187627: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187628: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187629: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187630: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187631: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187632: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187633: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187634: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187635: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187636: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187637: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187638: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187639: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187640: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187641: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187642: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187643: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187644: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187645: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187646: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187647: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n",
      "Error inserting row 187648: (\"A TVP's rows must be Sequence objects.\", 'HY000')\n"
     ]
    }
   ],
   "source": [
    "with pyodbc.connect(conn_str) as cnxn:\n",
    "    with cnxn.cursor() as cursor:\n",
    "        for index, row in nye.iterrows():\n",
    "            course_id= row['value.course_id'],\n",
    "            enrollment_id= row['key.id'],\n",
    "            user_id= row['value.user_id'],\n",
    "            sis_user_id= \"\",\n",
    "            enrollment_type= row['value.type'],\n",
    "            created_at= row['value.created_at'],\n",
    "            updated_at= row['value.updated_at'],\n",
    "            enrollment_state= str(row['value.workflow_state']),\n",
    "            total_activity_time= str(row['value.total_activity_time']),\n",
    "            last_activity_at= str(row['value.last_activity_at'])\n",
    "            try:\n",
    "                merge_query = \"\"\"\n",
    "                                MERGE INTO [stg].[Canvas_Enrollments] AS target\n",
    "                                USING (SELECT ?, ?, ?, ?, ?, CONVERT(datetime, ?, 127), CONVERT(datetime, ?, 127), ?, ?, CONVERT(datetime, ?, 127)) AS source (\n",
    "                                    [enrollment_id],\n",
    "                                    [user_id],\n",
    "                                    [sis_user_id],\n",
    "                                    [course_id],\n",
    "                                    [type],\n",
    "                                    [created_at],\n",
    "                                    [updated_at],\n",
    "                                    [enrollment_state],\n",
    "                                    [total_activity_time],\n",
    "                                    [last_activity_at]\n",
    "                                )\n",
    "                                ON target.[enrollment_id] = source.[enrollment_id]\n",
    "                                WHEN MATCHED THEN\n",
    "                                    UPDATE SET target.[user_id]= source.[user_id],\n",
    "                                        target.[sis_user_id] = source.[sis_user_id],\n",
    "                                        target.[course_id] = source.[course_id],\n",
    "                                        target.[type] = source.[type],\n",
    "                                        target.[created_at] = source.[created_at],\n",
    "                                        target.[updated_at] = source.[updated_at],\n",
    "                                        target.[enrollment_state] = source.[enrollment_state],\n",
    "                                        target.[total_activity_time] = source.[total_activity_time],\n",
    "                                        target.[last_activity_at] = source.[last_activity_at]\n",
    "                                WHEN NOT MATCHED THEN\n",
    "                                    INSERT ([enrollment_id],\n",
    "                                        [user_id],\n",
    "                                        [sis_user_id],\n",
    "                                        [course_id],\n",
    "                                        [type],\n",
    "                                        [created_at],\n",
    "                                        [updated_at],\n",
    "                                        [enrollment_state],\n",
    "                                        [total_activity_time],\n",
    "                                        [last_activity_at]\n",
    "                                    )\n",
    "                                    VALUES (source.[enrollment_id],\n",
    "                                        source.[user_id],\n",
    "                                        source.[sis_user_id],\n",
    "                                        source.[course_id],\n",
    "                                        source.[type],\n",
    "                                        source.[created_at],\n",
    "                                        source.[updated_at],\n",
    "                                        source.[enrollment_state],\n",
    "                                        source.[total_activity_time],\n",
    "                                        source.[last_activity_at]\n",
    "                                    );\n",
    "                            \"\"\"\n",
    "                cursor.execute(merge_query, (enrollment_id, user_id, sis_user_id, course_id, enrollment_type, created_at, updated_at, enrollment_state, total_activity_time, last_activity_at))\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting row {index}: {e}\")\n",
    "        cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'course_id': '29020',\n",
       " 'enrollment_id': '1453477',\n",
       " 'user_id': '109225',\n",
       " 'sis_user_id': '',\n",
       " 'type': 'StudentEnrollment',\n",
       " 'created_at': '2024-10-30T04:57:53.611Z',\n",
       " 'updated_at': '2024-10-30T04:57:53.611Z',\n",
       " 'enrollment_state': 'active',\n",
       " 'total_activity_time': 'nan',\n",
       " 'last_activity_at': 'nan'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
